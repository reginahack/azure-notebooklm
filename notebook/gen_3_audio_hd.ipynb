{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate Audio (HD Voice)\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/high-definition-voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rh/workspace/ai_podcast/azure-notebooklm/notebook\n",
      "Looking for .env at: /Users/rh/workspace/ai_podcast/azure-notebooklm/.env\n",
      "✓ .env file loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Load .env from parent directory (where the app.py is located)\n",
    "env_path = os.path.join(os.path.dirname(os.getcwd()), '.env')\n",
    "print(f\"Looking for .env at: {env_path}\")\n",
    "\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    print(\"✓ .env file loaded successfully\")\n",
    "else:\n",
    "    print(\"✗ .env file not found\")\n",
    "    # Try alternative path\n",
    "    alt_env_path = '../.env'\n",
    "    if os.path.exists(alt_env_path):\n",
    "        load_dotenv(alt_env_path)\n",
    "        print(f\"✓ .env file loaded from {alt_env_path}\")\n",
    "    else:\n",
    "        print(\"✗ .env file not found in alternative location either\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'Host (Alice)',\n",
       "  'text': \"Welcome to the podcast, Dr. Vaswani! I'm thrilled to have you here today.\"},\n",
       " {'speaker': 'Guest',\n",
       "  'text': \"Thank you, Alice! It's a pleasure to join you and discuss the Transformer model.\"},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': \"Let's dive right in. The Transformer—why is it considered a breakthrough in AI?\"},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Well, it revolutionized sequence modeling by using attention mechanisms instead of recurrence.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'No recurrence or convolutions? That sounds like a bold departure from tradition!'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Exactly. This approach allows for parallelization, making training faster and more efficient.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Could you explain how attention works in this context? Break it down for us.'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Sure! Attention identifies relationships between inputs and outputs, regardless of their distance.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': \"Ah, and this is where 'self-attention' comes into play, right?\"},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Yes, self-attention relates positions within a sequence to compute its representation effectively.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'How does this compare to traditional RNNs or CNNs in handling dependencies?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'It reduces path lengths for dependencies, making it easier to learn long-range relationships.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': \"That's fascinating! And it’s faster too, correct?\"},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Absolutely. The parallelizable nature of attention cuts down training time significantly.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Your model achieved state-of-the-art results in translation tasks. Can you share more?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'On English-to-German, we reached 28.4 BLEU, surpassing previous models by over 2 BLEU.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Impressive! And it trained faster as well, didn’t it?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Yes, just 3.5 days on eight GPUs, which is much quicker than traditional approaches.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'How did it perform on English-to-French translation?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'We achieved 41.8 BLEU, setting a new single-model record for translation quality.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Wow! What’s the secret behind these remarkable results?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Multi-head attention is crucial. It lets the model focus on multiple aspects simultaneously.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'And positional encoding—how does that factor in?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'It provides order information to sequences, which is vital since the model lacks recurrence.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'You also applied the Transformer to parsing tasks. How did it perform there?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'It excelled, even with limited training data, showcasing its versatility across tasks.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'What’s next for the Transformer? Any exciting developments on the horizon?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'We’re exploring its application to non-text modalities like images, audio, and video.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'That sounds promising! Could it redefine those fields as well?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Potentially, yes. Attention mechanisms are powerful tools across diverse applications.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Before we wrap up, what’s the key takeaway for our listeners today?'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'The Transformer shows that simplicity in design can lead to groundbreaking efficiency.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Thank you, Dr. Vaswani, for sharing your insights. This has been truly enlightening!'},\n",
       " {'speaker': 'Guest',\n",
       "  'text': 'Thank you, Alice! It’s been a pleasure discussing this with you.'},\n",
       " {'speaker': 'Host (Alice)',\n",
       "  'text': 'Listeners, stay tuned for more episodes exploring AI innovations. Take care!'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"1706.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jsfile = f.read()\n",
    "\n",
    "conversation = json.loads(jsfile)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HD Options\n",
    "\n",
    "Default [temperature parameter](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/high-definition-voices#how-to-use-azure-ai-speech-hd-voices) is 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ssml(host_voice, guest_voice, temperature=1.0):\n",
    "    \n",
    "    ssml = \"<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='https://www.w3.org/2001/mstts' xml:lang='en-US'>\"\n",
    "    for r in conversation:\n",
    "        #print(row.to_dict())\n",
    "        \n",
    "        if r['speaker'] == 'Host (Alice)':\n",
    "            ssml += f\"\\n<voice name='{host_voice}' parameters='temperature={temperature}'>{r['text']}</voice>\"\n",
    "        else:\n",
    "            ssml += f\"\\n<voice name='{guest_voice}' parameters='temperature={temperature}'>{r['text']}</voice>\"\n",
    "    ssml += \"\\n</speak>\"\n",
    "\n",
    "    #print(ssml)\n",
    "\n",
    "    return ssml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Key: [SET]\n",
      "Speech Region: westeurope\n",
      "Speech SDK configured successfully\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "\n",
    "# Debug: Check environment variables\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "service_region = os.getenv('SPEECH_REGION')\n",
    "\n",
    "print(f\"Speech Key: {'[SET]' if speech_key else '[NOT SET]'}\")\n",
    "print(f\"Speech Region: {service_region}\")\n",
    "\n",
    "if not speech_key or not service_region:\n",
    "    print(\"ERROR: Missing required environment variables SPEECH_KEY and/or SPEECH_REGION\")\n",
    "    print(\"Please check your .env file\")\n",
    "else:\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, \"logs\")\n",
    "    print(\"Speech SDK configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_filename(length=8):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def generate_podcast(ssml, filename=None):\n",
    "    if filename is None:\n",
    "        temporary_file= \"./\" + generate_random_filename() + \".wav\"\n",
    "    else:\n",
    "        temporary_file = filename\n",
    "        \n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=temporary_file)\n",
    "\n",
    "    # Creates a speech synthesizer using the Azure Speech Service.\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesis was successful. Audio was written to '{}'\".format(temporary_file))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "        print(\"Did you update the subscription info?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HD voice (optimized for podcasts)\n",
    "# host_voice = 'en-us-Ava3:DragonHDLatestNeural'\n",
    "# guest_voice = 'en-us-Andrew3:DragonHDLatestNeural'\n",
    "\n",
    "# HD voice (optimized for conversational content) - works best for a 2-person podcast\n",
    "host_voice = 'en-us-Emma2:DragonHDLatestNeural'\n",
    "guest_voice = 'en-us-Andrew2:DragonHDLatestNeural'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesis was successful. Audio was written to '1706.wav'\n",
      "Info: on_underlying_io_bytes_received: Close frame received\n",
      "Info: on_underlying_io_bytes_received: closing underlying io.\n",
      "Info: on_underlying_io_close_complete: uws_state: 6.\n"
     ]
    }
   ],
   "source": [
    "temp = 0.9\n",
    "ssml = generate_ssml(host_voice, guest_voice, temp)\n",
    "generate_podcast(ssml, \"1706.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
